{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "496e5093-5cac-42b1-bf76-7ea362a2f65c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "classifier = Sequential()\n",
    "\n",
    "classifier.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1), input_shape=(150, 150, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Conv2D(64, kernel_size=(5, 5), strides=(1, 1), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "classifier.add(Flatten())\n",
    "\n",
    "classifier.add(Dense(64, activation='relu'))\n",
    "\n",
    "classifier.add(Dense(15, activation='softmax'))\n",
    "\n",
    "classifier.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fb39cea-20cb-4a34-9642-007ff292e068",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 684 images belonging to 15 classes.\n",
      "Found 75 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras_vggface.utils import preprocess_input\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1/255, # масштабирование значений пикселей в диапазон от 0 до 1\n",
    "    rotation_range=20, # угол поворота изображения\n",
    "    width_shift_range=0.1, # смещение изображения по горизонтали\n",
    "    height_shift_range=0.1, # смещение изображения по вертикали\n",
    "    shear_range=0.2, # сдвиг изображения\n",
    "    zoom_range=0.2, # масштабирование изображения\n",
    "    vertical_flip=True,\n",
    "    horizontal_flip=True, # отражение изображения по горизонтали\n",
    "    brightness_range= (0.5,1.8),\n",
    "    fill_mode='nearest', # заполнение пикселей после преобразований\n",
    "    preprocessing_function=preprocess_input # препроцессинг изображений для распознавания лиц\n",
    "\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_generator = datagen.flow_from_directory('../фото/tt/train/',\n",
    "                                                    target_size=(150, 150),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical',\n",
    "                                                    shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory('../фото/tt/test/',\n",
    "                                                  target_size=(150, 150),\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='categorical',\n",
    "                                                  shuffle=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b52f01c5-d7bb-4c79-b8a6-324ada9e45a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30dccd40-8ff8-45d3-b310-7d399362d5dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "21/21 [==============================] - 63s 3s/step - loss: 2.6788 - accuracy: 0.1334 - val_loss: 2.8431 - val_accuracy: 0.0938\n",
      "Epoch 2/50\n",
      "21/21 [==============================] - 60s 3s/step - loss: 2.3503 - accuracy: 0.2699 - val_loss: 2.9270 - val_accuracy: 0.0312\n",
      "Epoch 3/50\n",
      "21/21 [==============================] - 57s 3s/step - loss: 1.9833 - accuracy: 0.3681 - val_loss: 2.8944 - val_accuracy: 0.1406\n",
      "Epoch 4/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.7346 - accuracy: 0.4663 - val_loss: 4.3176 - val_accuracy: 0.0938\n",
      "Epoch 5/50\n",
      "21/21 [==============================] - 58s 3s/step - loss: 1.3999 - accuracy: 0.5565 - val_loss: 3.8305 - val_accuracy: 0.0781\n",
      "Epoch 6/50\n",
      "21/21 [==============================] - 56s 3s/step - loss: 1.3025 - accuracy: 0.5844 - val_loss: 3.9353 - val_accuracy: 0.1562\n"
     ]
    }
   ],
   "source": [
    "history = classifier.fit(train_generator,\n",
    "                         steps_per_epoch=train_generator.n // train_generator.batch_size,\n",
    "                         epochs=50,\n",
    "                         validation_data=test_generator,\n",
    "                         validation_steps=test_generator.n // test_generator.batch_size,\n",
    "                         callbacks=[earlystop, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f01af0-92a5-46fd-81df-5af2679ec4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
